{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/stefan-it/nmt-en-vi/raw/master/data/train-en-vi.tgz\n",
    "# !tar -zxf train-en-vi.tgz\n",
    "# !wget https://github.com/stefan-it/nmt-en-vi/raw/master/data/dev-2012-en-vi.tgz\n",
    "# !tar -zxf dev-2012-en-vi.tgz\n",
    "# !wget https://github.com/stefan-it/nmt-en-vi/raw/master/data/test-2013-en-vi.tgz\n",
    "# !tar -zxf test-2013-en-vi.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install malaya --no-deps\n",
    "# !pip3 install bert-tensorflow\n",
    "# !pip3 install toolz\n",
    "# !pip3 install pysastrawi\n",
    "# !pip3 install fuzzywuzzy\n",
    "# !pip3 install xgboost\n",
    "# !pip3 install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya\n",
    "import re\n",
    "\n",
    "tokenizer = malaya.preprocessing.SocialTokenizer().tokenize\n",
    "\n",
    "def is_number_regex(s):\n",
    "    if re.match(\"^\\d+?\\.\\d+?$\", s) is None:\n",
    "        return s.isdigit()\n",
    "    return True\n",
    "\n",
    "def preprocessing(string):\n",
    "    tokenized = tokenizer(string)\n",
    "    tokenized = ['<NUM>' if is_number_regex(w) else w for w in tokenized]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133317, 133317)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.en') as fopen:\n",
    "    train_english = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "with open('train.vi') as fopen:\n",
    "    train_vietnam = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "len(train_english), len(train_vietnam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133317/133317 [00:16<00:00, 8000.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(train_english))):\n",
    "    train_english[i] = ' '.join(preprocessing(train_english[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133317/133317 [00:22<00:00, 6040.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_vietnam))):\n",
    "    train_vietnam[i] = ' '.join(preprocessing(train_vietnam[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1553, 1553)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tst2012.en') as fopen:\n",
    "    test_english_2012 = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "with open('tst2012.vi') as fopen:\n",
    "    test_vietnam_2012 = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "len(test_english_2012), len(test_vietnam_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1553/1553 [00:00<00:00, 7548.44it/s]\n",
      "100%|██████████| 1553/1553 [00:00<00:00, 6857.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_english_2012))):\n",
    "    test_english_2012[i] = ' '.join(preprocessing(test_english_2012[i]))\n",
    "    \n",
    "for i in tqdm(range(len(test_vietnam_2012))):\n",
    "    test_vietnam_2012[i] = ' '.join(preprocessing(test_vietnam_2012[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1268, 1268)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tst2013.en') as fopen:\n",
    "    test_english_2013 = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "with open('tst2013.vi') as fopen:\n",
    "    test_vietnam_2013 = fopen.read().split('\\n')[:-1]\n",
    "    \n",
    "len(test_english_2013), len(test_vietnam_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268/1268 [00:00<00:00, 7760.10it/s]\n",
      "100%|██████████| 1268/1268 [00:00<00:00, 5696.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_english_2013))):\n",
    "    test_english_2013[i] = ' '.join(preprocessing(test_english_2013[i]))\n",
    "    \n",
    "for i in tqdm(range(len(test_vietnam_2013))):\n",
    "    test_vietnam_2013[i] = ' '.join(preprocessing(test_vietnam_2013[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = [], []\n",
    "for i in range(len(train_english)):\n",
    "    if len(train_english[i].split()) > 250:\n",
    "        continue\n",
    "    train_X.append(train_english[i])\n",
    "    train_Y.append(train_vietnam[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = [], []\n",
    "for i in range(len(test_english_2012)):\n",
    "    if len(test_english_2012[i].split()) > 250:\n",
    "        continue\n",
    "    test_X.append(test_english_2012[i])\n",
    "    test_Y.append(test_vietnam_2012[i])\n",
    "    \n",
    "for i in range(len(test_english_2013)):\n",
    "    if len(test_english_2013[i].split()) > 250:\n",
    "        continue\n",
    "    test_X.append(test_english_2013[i])\n",
    "    test_Y.append(test_vietnam_2013[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X) + len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Làm sao tôi có thể trình bày trong <NUM> phút về sợi dây liên kết những người phụ nữ qua ba thế hệ , về việc làm thế nào những sợi dây mạnh mẽ đáng kinh ngạc ấy đã níu chặt lấy cuộc sống của một cô bé bốn tuổi co quắp với đứa em gái nhỏ của cô bé , với mẹ và bà trong suốt năm ngày đêm trên con thuyền nhỏ lênh đênh trên Biển Đông hơn <NUM> năm trước , những sợi dây liên kết đã níu lấy cuộc đời cô bé ấy và không bao giờ rời đi - - cô bé ấy giờ sống ở San Francisco và đang nói chuyện với các bạn hôm nay ?',\n",
       " 'Câu chuyện này chưa kết thúc .',\n",
       " 'Nó là một trò chơi ghép hình vẫn đang được xếp .',\n",
       " 'Hãy để tôi kể cho các bạn về vài mảnh ghép nhé .',\n",
       " 'Hãy tưởng tượng mảnh đầu tiên : một người đàn ông đốt cháy sự nghiệp cả đời mình .']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(train_X))\n",
    "    \n",
    "english = yttm.BPE.train(data='text.txt', vocab_size=32000, model='english.model',\n",
    "              pad_id=0, unk_id=2, bos_id=3, eos_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(train_Y))\n",
    "    \n",
    "vietnam = yttm.BPE.train(data='text.txt', vocab_size=32000, model='vietnam.model',\n",
    "              pad_id=0, unk_id=2, bos_id=3, eos_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = english.encode(train_X, output_type=yttm.OutputType.ID)\n",
    "train_X = [i + [1] for i in train_X]\n",
    "test_X = english.encode(test_X, output_type=yttm.OutputType.ID)\n",
    "test_X = [i + [1] for i in test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = vietnam.encode(train_Y, output_type=yttm.OutputType.ID)\n",
    "test_Y = vietnam.encode(test_Y, output_type=yttm.OutputType.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train-test-bpe.json', 'w') as fopen:\n",
    "    json.dump({'train_X': train_X, 'train_Y': train_Y,\n",
    "              'test_X': test_X,\n",
    "              'test_Y': test_Y}, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
