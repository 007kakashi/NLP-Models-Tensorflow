{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ctexts.json','r') as fopen:\n",
    "    ctexts = json.loads(fopen.read())[:100]\n",
    "    \n",
    "with open('headlines.json','r') as fopen:\n",
    "    headlines = json.loads(fopen.read())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 6546\n",
      "Most common words [('the', 2378), ('comma', 1806), ('dot', 1774), ('and', 981), ('to', 951), ('of', 910)]\n",
      "Sample data [4, 865, 7, 918, 261, 12, 158, 2927, 10, 582] ['the', 'daman', 'and', 'diu', 'administration', 'on', 'wednesday', 'withdrew', 'a', 'circular']\n"
     ]
    }
   ],
   "source": [
    "concat_from = ' '.join(ctexts).split()\n",
    "vocabulary_size_from = len(list(set(concat_from)))\n",
    "data_from, count_from, dictionary_from, rev_dictionary_from = build_dataset(concat_from, vocabulary_size_from)\n",
    "print('vocab from size: %d'%(vocabulary_size_from))\n",
    "print('Most common words', count_from[4:10])\n",
    "print('Sample data', data_from[:10], [rev_dictionary_from[i] for i in data_from[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab to size: 654\n",
      "Most common words [('to', 34), ('in', 28), ('for', 17), ('s', 14), ('of', 13), ('comma', 13)]\n",
      "Sample data [100, 16, 89, 407, 241, 67, 5, 191, 86, 458] ['daman', 'and', 'diu', 'revokes', 'mandatory', 'rakshabandhan', 'in', 'offices', 'order', 'malaika']\n"
     ]
    }
   ],
   "source": [
    "concat_to = ' '.join(headlines).split()\n",
    "vocabulary_size_to = len(list(set(concat_to)))\n",
    "data_to, count_to, dictionary_to, rev_dictionary_to = build_dataset(concat_to, vocabulary_size_to)\n",
    "print('vocab to size: %d'%(vocabulary_size_to))\n",
    "print('Most common words', count_to[4:10])\n",
    "print('Sample data', data_to[:10], [rev_dictionary_to[i] for i in data_to[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daman and diu revokes mandatory rakshabandhan in offices order EOS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(headlines)):\n",
    "    headlines[i] = headlines[i] + ' EOS'\n",
    "headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary_from['GO']\n",
    "PAD = dictionary_from['PAD']\n",
    "EOS = dictionary_from['EOS']\n",
    "UNK = dictionary_from['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_idx(corpus, dic):\n",
    "    X = []\n",
    "    for i in corpus:\n",
    "        ints = []\n",
    "        for k in i.split():\n",
    "            try:\n",
    "                ints.append(dic[k])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                ints.append(UNK)\n",
    "        X.append(ints)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = str_idx(ctexts, dictionary_from)\n",
    "Y = str_idx(headlines, dictionary_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size, \n",
    "                 from_dict_size, to_dict_size, batch_size,\n",
    "                 grad_clip=5.0, beam_width=5, force_teaching_ratio=0.5):\n",
    "        \n",
    "        def lstm_cell(size, reuse=False):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size, initializer=tf.orthogonal_initializer(),reuse=reuse)\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_seq_len = tf.placeholder(tf.int32, [None])\n",
    "        self.Y_seq_len = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([from_dict_size, embedded_size], -1, 1))\n",
    "        decoder_embeddings = tf.Variable(tf.random_uniform([to_dict_size, embedded_size], -1, 1))\n",
    "        encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        \n",
    "        for n in range(num_layers):\n",
    "            (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = lstm_cell(size_layer // 2),\n",
    "                cell_bw = lstm_cell(size_layer // 2),\n",
    "                inputs = encoder_embedded,\n",
    "                sequence_length = self.X_seq_len,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_%d'%(n))\n",
    "            encoder_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "        bi_state_c = tf.concat((state_fw.c, state_bw.c), -1)\n",
    "        bi_state_h = tf.concat((state_fw.h, state_bw.h), -1)\n",
    "        bi_lstm_state = tf.nn.rnn_cell.LSTMStateTuple(c=bi_state_c, h=bi_state_h)\n",
    "        encoder_state = tuple([bi_lstm_state] * num_layers)\n",
    "        \n",
    "        with tf.variable_scope('decode'):\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units = size_layer, \n",
    "            memory = encoder_embedded,\n",
    "            memory_sequence_length = self.X_seq_len)\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer) for _ in range(num_layers)]),\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = size_layer)\n",
    "            main = tf.strided_slice(self.Y, [0, 0], [batch_size, -1], [1, 1])\n",
    "            decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
    "            training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "            inputs = tf.nn.embedding_lookup(decoder_embeddings, decoder_input),\n",
    "                sequence_length = self.Y_seq_len,\n",
    "                embedding = decoder_embeddings,\n",
    "                sampling_probability = 1 - force_teaching_ratio,\n",
    "                time_major = False)\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = decoder_cell,\n",
    "                helper = training_helper,\n",
    "                initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),\n",
    "                output_layer = tf.layers.Dense(to_dict_size))\n",
    "            training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = training_decoder,\n",
    "                impute_finished = True,\n",
    "                maximum_iterations = tf.reduce_max(self.Y_seq_len))\n",
    "            self.logits = training_decoder_output.rnn_output\n",
    "            \n",
    "        with tf.variable_scope('decode', reuse=True):\n",
    "            encoder_out_tiled = tf.contrib.seq2seq.tile_batch(encoder_embedded, beam_width)\n",
    "            encoder_state_tiled = tf.contrib.seq2seq.tile_batch(encoder_state, beam_width)\n",
    "            X_seq_len_tiled = tf.contrib.seq2seq.tile_batch(self.X_seq_len, beam_width)\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units = size_layer, \n",
    "                memory = encoder_out_tiled,\n",
    "                memory_sequence_length = X_seq_len_tiled)\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer, reuse=True) for _ in range(num_layers)]),\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = size_layer)\n",
    "            predicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell = decoder_cell,\n",
    "                embedding = decoder_embeddings,\n",
    "                start_tokens = tf.tile(tf.constant([GO], dtype=tf.int32), [batch_size]),\n",
    "                end_token = EOS,\n",
    "                initial_state = decoder_cell.zero_state(batch_size * beam_width, tf.float32).clone(cell_state = encoder_state_tiled),\n",
    "                beam_width = beam_width,\n",
    "                output_layer = tf.layers.Dense(to_dict_size, _reuse=True),\n",
    "                length_penalty_weight = 0.0)\n",
    "            predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = predicting_decoder,\n",
    "                impute_finished = False,\n",
    "                maximum_iterations = tf.reduce_max(self.X_seq_len)//3)\n",
    "            self.predicting_ids = predicting_decoder_output.predicted_ids[:, :, 0]\n",
    "        \n",
    "        masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)\n",
    "        self.cost = tf.contrib.seq2seq.sequence_loss(logits = self.logits,\n",
    "                                                     targets = self.Y,\n",
    "                                                     weights = masks)\n",
    "        params = tf.trainable_variables()\n",
    "        gradients = tf.gradients(self.cost, params)\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(gradients, grad_clip)\n",
    "        self.optimizer = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 512\n",
    "num_layers = 2\n",
    "embedded_size = 128\n",
    "batch_size = 16\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Summarization(size_layer, num_layers, embedded_size, len(dictionary_from), \n",
    "                len(dictionary_to), batch_size)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int, maxlen=500):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = min(max([len(sentence) for sentence in sentence_batch]),maxlen)\n",
    "    for sentence in sentence_batch:\n",
    "        sentence = sentence[:maxlen]\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens\n",
    "\n",
    "def check_accuracy(logits, Y):\n",
    "    acc = 0\n",
    "    for i in range(logits.shape[0]):\n",
    "        internal_acc = 0\n",
    "        count = 0\n",
    "        for k in range(len(Y[i])):\n",
    "            try:\n",
    "                if Y[i][k] == logits[i][k]:\n",
    "                    internal_acc += 1\n",
    "                count += 1\n",
    "                if Y[i][k] == EOS:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "        acc += (internal_acc / count)\n",
    "    return acc / logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 6.149925, valid loss 6.090511\n",
      "expected output: mumbai court convicts fifteen somali pirates in two thousand and eleven case\n",
      "predicted output: \n",
      "epoch: 1, avg loss: 6.587512, avg accuracy: 0.000000 \n",
      "\n",
      "epoch 2, train loss 5.848755, valid loss 5.822256\n",
      "expected output: food regulator planning leftover banks to feed hungry people\n",
      "predicted output: to to to\n",
      "epoch: 2, avg loss: 6.006247, avg accuracy: 0.027927 \n",
      "\n",
      "epoch 3, train loss 5.693542, valid loss 5.574854\n",
      "expected output: us prez donald trump called white house a real dump report\n",
      "predicted output: to to to to in\n",
      "epoch: 3, avg loss: 5.714936, avg accuracy: 0.013810 \n",
      "\n",
      "epoch 4, train loss 5.549518, valid loss 5.378962\n",
      "expected output: sunbathers killed as plane hits them while landing on beach\n",
      "predicted output: to to to to to to\n",
      "epoch: 4, avg loss: 5.523256, avg accuracy: 0.043005 \n",
      "\n",
      "epoch 5, train loss 5.334972, valid loss 5.763390\n",
      "expected output: no info on hiring class twelve boy on twelve lakh per month google\n",
      "predicted output: to to to to in\n",
      "epoch: 5, avg loss: 5.350935, avg accuracy: 0.058378 \n",
      "\n",
      "epoch 6, train loss 5.129689, valid loss 4.801401\n",
      "expected output: trump campaign was dysfunctional for any collusion kushner\n",
      "predicted output: to to to to to\n",
      "epoch: 6, avg loss: 5.137946, avg accuracy: 0.066037 \n",
      "\n",
      "epoch 7, train loss 4.821293, valid loss 6.231566\n",
      "expected output: twenty stuck in gurugram mall lift for ninety mins rescued\n",
      "predicted output: delhi delhi delhi in in in\n",
      "epoch: 7, avg loss: 4.862586, avg accuracy: 0.085340 \n",
      "\n",
      "epoch 8, train loss 4.640774, valid loss 4.172898\n",
      "expected output: nineteen gurugram buildings to pay property tax over free parking\n",
      "predicted output: nineteen nineteen to to to pay pay pay over over\n",
      "epoch: 8, avg loss: 4.579956, avg accuracy: 0.112723 \n",
      "\n",
      "epoch 9, train loss 4.484404, valid loss 7.173267\n",
      "expected output: vehicles consume one dot five times more fuel on crowded roads study\n",
      "predicted output: vehicles consume comma comma comma comma comma in\n",
      "epoch: 9, avg loss: 4.440921, avg accuracy: 0.122109 \n",
      "\n",
      "epoch 10, train loss 4.402038, valid loss 3.858521\n",
      "expected output: mumbai s juhu beach to be redeveloped\n",
      "predicted output: mumbai to to to to to be to to\n",
      "epoch: 10, avg loss: 4.155221, avg accuracy: 0.146307 \n",
      "\n",
      "epoch 11, train loss 3.914672, valid loss 3.689224\n",
      "expected output: egypt s islamic authority sets up fatwa kiosk at metro\n",
      "predicted output: suffering suffering a a a a\n",
      "epoch: 11, avg loss: 3.910887, avg accuracy: 0.188819 \n",
      "\n",
      "epoch 12, train loss 3.353713, valid loss 3.276488\n",
      "expected output: chopper flying critically low led to two thousand and fifteen bombay high crash\n",
      "predicted output: chopper critically low low three in in\n",
      "epoch: 12, avg loss: 3.571237, avg accuracy: 0.182754 \n",
      "\n",
      "epoch 13, train loss 2.797432, valid loss 4.325958\n",
      "expected output: jandk cops ask pak high commission to claim let leader s body\n",
      "predicted output: jandk ask ask to to to be to to\n",
      "epoch: 13, avg loss: 3.037867, avg accuracy: 0.293797 \n",
      "\n",
      "epoch 14, train loss 2.306372, valid loss 2.266898\n",
      "expected output: rape accused kills self after order to drink victim s urine\n",
      "predicted output: rape accused kills kills kills in in in\n",
      "epoch: 14, avg loss: 2.497915, avg accuracy: 0.345787 \n",
      "\n",
      "epoch 15, train loss 1.941184, valid loss 2.326595\n",
      "expected output: call devastated his life mom of boy who got google offer\n",
      "predicted output: call call his his mom of of of got\n",
      "epoch: 15, avg loss: 2.061958, avg accuracy: 0.437200 \n",
      "\n",
      "epoch 16, train loss 1.588105, valid loss 1.489401\n",
      "expected output: plane built for russian airline may be next us air force one\n",
      "predicted output: built built for russian airline next next next\n",
      "epoch: 16, avg loss: 1.732925, avg accuracy: 0.498330 \n",
      "\n",
      "epoch 17, train loss 1.389943, valid loss 1.400274\n",
      "expected output: indian athlete indicted on sex abuse charge in us\n",
      "predicted output: indian athlete on sex sex charge\n",
      "epoch: 17, avg loss: 1.556250, avg accuracy: 0.499899 \n",
      "\n",
      "epoch 18, train loss 1.903633, valid loss 1.937039\n",
      "expected output: rape accused kills self after order to drink victim s urine\n",
      "predicted output: rape accused kills kills self self order drink drink drink s urine\n",
      "epoch: 18, avg loss: 1.681562, avg accuracy: 0.449859 \n",
      "\n",
      "epoch 19, train loss 2.345290, valid loss 1.785238\n",
      "expected output: easyjet passengers stranded in greece due to mating turtles\n",
      "predicted output: easyjet stranded in greece in turtles turtles turtles\n",
      "epoch: 19, avg loss: 2.217373, avg accuracy: 0.339770 \n",
      "\n",
      "epoch 20, train loss 1.603107, valid loss 1.288769\n",
      "expected output: email prankster fooled fired trump media chief thrice\n",
      "predicted output: email prankster fooled fired fired media media chief\n",
      "epoch: 20, avg loss: 1.820879, avg accuracy: 0.400571 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    for k in range(0, (len(train_X) // batch_size) * batch_size, batch_size):\n",
    "        batch_x, seq_x = pad_sentence_batch(train_X[k: k+batch_size], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(train_Y[k: k+batch_size], PAD)\n",
    "        predicted, loss, _ = sess.run([model.predicting_ids, model.cost, model.optimizer], \n",
    "                                      feed_dict={model.X:batch_x,\n",
    "                                                model.Y:batch_y,\n",
    "                                                model.X_seq_len:seq_x,\n",
    "                                                model.Y_seq_len:seq_y})\n",
    "        \n",
    "        total_loss += loss\n",
    "        total_accuracy += check_accuracy(predicted,batch_y)\n",
    "        \n",
    "    rand = np.random.randint(0, len(train_X)-batch_size)\n",
    "    batch_x, seq_x = pad_sentence_batch(train_X[rand:rand+batch_size], PAD)\n",
    "    batch_y, seq_y = pad_sentence_batch(train_Y[rand:rand+batch_size], PAD)\n",
    "    predicted, test_loss = sess.run([model.predicting_ids,model.cost], \n",
    "                                    feed_dict={model.X:batch_x,\n",
    "                                               model.Y:batch_y,\n",
    "                                               model.X_seq_len:seq_x,\n",
    "                                               model.Y_seq_len:seq_y})\n",
    "    print('epoch %d, train loss %f, valid loss %f'%(i+1,loss,test_loss))\n",
    "    print('expected output:',' '.join([rev_dictionary_to[n] for n in batch_y[0] if n not in [-1,0,1,2,3]]))\n",
    "    print('predicted output:',' '.join([rev_dictionary_to[n] for n in predicted[0] if n not in [-1,0,1,2,3]]))\n",
    "            \n",
    "    total_loss /= (len(train_X) // batch_size)\n",
    "    total_accuracy /= (len(train_X) // batch_size)\n",
    "    print('epoch: %d, avg loss: %f, avg accuracy: %f'%(i+1, total_loss, total_accuracy),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
